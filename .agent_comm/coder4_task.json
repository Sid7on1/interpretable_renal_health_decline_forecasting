{
  "agent_id": "coder4",
  "task_id": "task_1",
  "files": [
    {
      "filename": "model.py",
      "purpose": "Defines the architecture of the Teacher LMM (T-LMM) and Student LMM (S-LMM) models.",
      "priority": "high",
      "dependencies": [
        "transformers",
        "torch"
      ],
      "key_functions": [
        "__init__",
        "forward"
      ],
      "estimated_lines": 300,
      "complexity": "medium"
    },
    {
      "filename": "explanation_generator.py",
      "purpose": "Generates explanations for the predicted eGFR values using abductive reasoning.",
      "priority": "high",
      "dependencies": [
        "transformers",
        "torch"
      ],
      "key_functions": [
        "generate_explanation"
      ],
      "estimated_lines": 250,
      "complexity": "medium"
    }
  ],
  "project_info": {
    "project_name": "Interpretable Renal Health Decline Forecasting",
    "project_type": "nlp",
    "description": "A collaborative framework for enhancing the predictive performance of open-source Large Multimodal Models (LMMs) in eGFR forecasting while providing clinically meaningful explanations.",
    "key_algorithms": [
      "Chain-of-Thought prompting",
      "Abductive reasoning",
      "Knowledge transfer",
      "Short-term memory mechanism"
    ],
    "main_libraries": [
      "transformers",
      "torch",
      "numpy",
      "pandas"
    ]
  },
  "paper_content": "PDF: cs.MA_2507.22464v1_Towards-Interpretable-Renal-Health-Decline-Forecas.pdf\nChunk: 1/1\n==================================================\n\n--- Page 1 ---\n Towards Interpretable Renal Health Decline \nForecasting via Multi -LMM Collaborative \nReasoning Framework  \nPeng -Yi Wu  \nDepartment of Information Management  \nNational Sun Yat -Sen University  \nKaohsiung, Taiwan  \npengyiwu0963@gmail.com  \n \nChantung Ku  \n Department of Information Management  \nNational Sun Yat -Sen University  \nKaohsiung, Taiwan  \nkuchantung@gmail.com Pei-Cing Huang  \n Department of Information Management  \nNational Sun Yat -Sen University  \n Kaohsiung, Taiwan  \npcpeicing@gmail.com  \n \nMing -Yen Lin  \n Kaohsiung Medical University Hospital  \nKaohsiung Medical University  \nKaohsiung, Taiwan  \n mingyenlin3@gmail.com  \n Ting -Yu Chen  \nDepartment of Information Management  \nNational Sun Yat -Sen University  \nKaohsiung, Taiwan  \nbrontotingyu@gmail.com  \n \nYihuang Kang  \n Department of Information Management  \nNational Sun Yat -Sen University  \nKaohsiung, Taiwan  \nykang@mis.nsysu.edu.tw\nAbstract\u2014Accurate and interpretable prediction of \nestimated glomerular filtration rate (eGFR) is essential for \nmanaging chronic kidney disease (CKD) and supporting clinical \ndecisions. Recent advances in Large Multimodal Models \n(LMMs) have shown strong potential in clinical prediction tasks \ndue to their ability to process visual and textual information. \nHowever, challenges related to deployment cost, data privacy, \nand model reliability hinder their adoption. In this study, we \npropose a collaborative framewor k that enhances the \nperformance of open -source LMMs for eGFR forecasting while \ngenerating clinically meaningful explanations. The framework \nincorporates visual knowledge transfer, abductive reasoning, \nand a short -term memory mechanism to enhance prediction  \naccuracy and interpretability.  Experimental results show that \nthe proposed framework achieves predictive performance and \ninterpretability comparable to proprietary models. It also \nprovides plausible clinical reasoning processes behind each \nprediction. Ou r method sheds new light on building AI systems \nfor healthcare that combine predictive accuracy with clinically \ngrounded interpretability.   \nKeywords \u2014Estimated Glomerular Filtration Rate, Large \nMultimodal Model, Explainable AI  \nI. INTRODUCTION  \nChronic kidney disease (CKD) is a growing global health \nconcern, with prevalence estimates ranging from 3% to 18% \nof the population [1]. The estimated glomerular filtration rate \n(eGFR) is an essential indicator for diagnosing CKD and \ndetecting early kidney damage. Accurate eGFR prediction can \nsupport early intervention and improve clinical outcomes  [2]. \nWhile traditional formulas, such as CKD -EPI [3],  are widely \nused to estimate kidney function, forecasting future kidney \nfunction decline is still a challenge. Recent machine learning \n(ML) models have shown promise in improving eGFR \nprediction, but many still fall short in capturing patient -\nspecific tr ends and often lack interpretability. For AI models \nto be adopted in clinical settings, transparency and \nexplainability are essential [4]. Clinicians must be able to \nunderstand how predictions are made to build trust and \nidentify potential errors. Therefore, predictive models should \nnot only be accurate but also provide explanations that reflect \nclinical reasoning and are easy to interpret . Large Language Models (LLMs) and Large Multimodal \nModels (LMMs) demonstrated remarkable capabilities in \nprocessing both language and multimodal data [5]. These \nmodels, pretrained on large -scale datasets, have shown \npotential in medical applications by integrating domain \nknowledge and generating interpretable outputs [6]. Their \nability to process text and visual data opens new opportunities \nfor improving eGFR prediction and explanation quality. \nRecent work has demonstrated that API -based, commercial \nLMMs can outperform traditional ML models in eGFR \nprediction when provide d with proper prompts [7]. However, \nconcerns over data privacy and high implementation costs \nlimit their clinical use. In contrast, open -source and open -\nweight LMMs are more suitable for local deployment but \noften struggle with complex clinical reasoning and visual \ninterpretation,  which may lead to unreliable or hallucinated \noutputs  [8]. These limitations highlight the need to develop a \nmore accurate and interpretable prediction framework to \nimprove these shortcomings . \nTo address these issues, this study proposes a collaborative \nmulti -LMM framework designed to improve the predictive \nperformance of open -source LMMs in eGFR forecasting \nwhile providing clinically meaningful explanations. Drawing \ninspiration from the concept  of Social Learning  [9], the \nframework facilitates knowledge transfer from stronger to \nsmaller models, improving their ability to interpret visuals and \ngenerate accurate predictions. To support transparent and \nclinically aligned reasoning, we integrate Chain -of-Thought \n(CoT) [10] reasoning to support step -by-step inference and \nintroduce a short -term memory mechanism to enhance \nconsistency and refinement across sequential predictions. We \nfurther adopt abductive reasoning [11] to generate data -driven \nand hypothesis -based explanations that offer objective \nperspectives and support comprehensive clinical \ninterpretations. The key contributions of this study are \nsummarized as follows : \n\uf09f We propose an LMM prediction framework \ncombining explanatory and causal reasoning for \nrenal function  forecasting.  \n\uf09f We explore and compare multiple techniques to \nenhance the performance of open -source models in \neGFR prediction tasks.  \n\n--- Page 2 ---\n\uf09f We incorporate structured abductive reasoning to \ngenerate clinical explanations that go beyond \nsurface -level data patterns and offer reasoning \nprocesses that are more compatible with clinical \nthinking.  \nThe rest of this paper is organized as follows: Section 2 \nreviews existing eGFR prediction methods and recent \nadvances in explainable and reasoning -enhanced AI \napproaches. Section 3 outlines our proposed framework, \nfollowed by Section 4, which presents the  results of our \nexperiments, comparing our approach to conventional ML \nmodels and different types of  LMMs. Section 5 discusses the \nlimitations of the current study and outlines directions for \nfuture research. Finally, Section 6 concludes the paper by \nsumm arizing the main contributions and practical \nimplications of the proposed framework . \nII. BACKGROUND  \nCKD is the seventh leading cause of death worldwide, \nwith mortality increasing by 50% from 2000 to 2019 and \nestimated to account for 5 to 11 million deaths annually [12]. \nThe eGFR is the primary clinical indicator of kidney function, \nplaying a critical role in diagnosing CKD. Derived from serum \ncreatinine and demographic variables such as age and sex, \neGFR calculated by formula provides a standard measure of \nrenal functio n. According to the National Kidney Foundation, \nregular eGFR monitoring is essential for individuals at risk, \nincluding those with diabetes, hypertension, or a family \nhistory of kidney disease [13]. \nTraditional formulas estimate eGFR using static variables. \nHowever, they are limited in capturing dynamic changes and \nare influenced by individual differences in muscle mass, diet, \nand comorbidities. More recently, ML models have been \nintroduced to enhance  eGFR prediction accuracy by \nincorporating multivariate and temporal data. Prior studies \nhave demonstrated the utility of ML in predicting eGFR \nthrough ultrasound -based kidney imaging, and the results \noutperformed traditional methods and were more accurate  \nthan most nephrologists\u2019 assessments [14]. Another utilized a \nrandom forest (RF) model to predict the progression of CKD \nusing demographics and laboratory data [15]. While these \nmodels offer potential for improved accuracy, several \nlimitations remain. Many suffered from limited \ngeneralizability due to training on single -center or region -\nspecific datasets. Furthermore, their performance is often \ndependent on large dat a volumes, and interpretability remains \na key barrier, particularly for deep learning models, which are \noften perceived as \u201cblack boxes \u201d, making it challenging for \nclinicians to understand prediction rationales.  \nModel transparency is particularly important in healthcare, \nwhere predictive outputs influence real -world medical \ndecisions [4]. This has led to growing interest in explainable \nAI (XAI) frameworks [16]. Techniques such as SHAP [17] \nand LIME [18] have been widely used to provide explanations \nby attributing model outputs to input features. A recent study \nfurther emphasizes the need for patient -specific \ninterpretations to support precise, individualized predictions, \nparticularly in practical applica tions where understanding the \nrationale behind a single patient\u2019s outcome is more critical \nthan identifying general population trends [19]. While these \ntechniques improve interpretability, many existing \ninterpretable methods still rely on surface -level correlations. \nFurthermore, they are limited in their ability to produce narrative, context -aware explanations that align with clinical \nreasoning . \nThe advancements in LLMs and LMMs have opened new \nopportunities for both predictive accuracy and interpretability \nin clinical tasks. For instance, Hegselmann et al. used LLMs \nto classify tabular healthcare data by serializing rows into \nnatural -language pro mpts [20]. However, performance may \nsuffer when input features exceed token limits. Our previous \nwork investigated modality transformation, where tabular \nclinical records are converted into visual formats that LMMs \ncan interpret more effectively [7]. This approach showed that \ncommercial models, such as Google Gemini [21] and GPT -4o \n[22], achieve superior performance in eGFR prediction when \ngiven visualized input and proper prompts . \nDespite their strong performance, commercial LMMs \nraise concerns regarding data privacy, cost, and limited local \ncontrol. In contrast, open -source LMMs offer the advantage \nof local deployment and enhanced data governance but often \nstruggle with complex rea soning and visual interpretation  [23], \nincreasing the risk of hallucinated outputs  [8]. Inspired by how \nhumans learn from one another, Scao et al. introduced the idea \nof social learning among LLMs, where models exchange \nknowledge using natural language [9]. This approach suggests \nthat LLM -based agents could benefit from interacting and \nlearning collaboratively to further enhance their performance. \nIn parallel, memory mechanisms have been  proposed to help \nmodels retain contextual information across time, improving \nconsistency and reasoning in sequential clinical tasks [24]. \nBuilding on these developments, recent research has also \nexplored ways to equip LLMs with human -like reasoning \nabilities. Among them, CoT prompting is recognized as a \nrepresentative method that encourages models to articulate \nintermediate reasoning steps i n natural languages [10]. This \napproach enhances the model\u2019s capacity for performing \ncomplex reasoning tasks. Formal reasoning paradigms, such \nas inductive, deductive, and abductive reasoning, have also \ngained attention. Abductive reasoning is considered a valuable \ncognitive tool  in clinical decision -making, particularly under \nuncertainty, as it supports individualized judgments by \nbridging population -level evidence and patient -specific \ncontexts [25]. However, the use of abductive reasoning to \ngenerate explanations remains relatively underexplored in the \nfield of AI in medicine. Simulating plausible clinical \nreasoning may offer value by enhancing the interpretability of \nmodel outputs and serving as a pedagogical tool for training \nmedical professionals. Therefore, our work explores \ntechniques such as knowledge transfer and memory \nmechanisms to enhance the prediction accuracy of open -\nsource LMMs for eGFR forecasting while generating \ninterpretable and cli nically meaningful explanations through \nabductive reasoning. We aim to enable more trustworthy, \ntransparent, and locally deployable AI systems for practical \nhealthcare use . \nIII. INTERPRETABLE TEACHER -STUDENT LMM FRAMEWORK \nFOR EGFR  FORECASTING  \nWe present our proposed framework, which aims to \nimprove open -source LMM eGFR prediction accuracy while \nproviding interpretable reasoning behind the forecasts. We \nintegrate two key components: Knowledge Transfer, which \nallows the model to learn visual unde rstanding from stronger \nvision -language models, and Short -term Memory, which \nenhances contextual continuity in reasoning and explanatio n\n\n--- Page 3 ---\nFig. 1.   Overview of the proposed two -stage eGFR prediction . \ngeneration. The framework, as illustrated in Figure 1, \nconsists of two stages: image interpretation and eGFR \nprediction with explanation .  \nIn the initial phase, each patient\u2019s historical eGFR \nmeasurements are first transformed into a series of de -\nidentified trend line charts to preserve privacy. These charts \nare input sequentially into a proprietary vision -language \nmodel, also called Teacher LMM (T -LMM), to extract \nclinically meaningful trends and summarize kidney function \nstatus. For each patient, we generate a sequence of M line \ncharts, where M is determined by the median number of \navailable eGFR measurements. The patient\u2019s m -th plot \ninclude s one additional data point compared to the (m \u20131)-th \nplot, specifically the next eGFR value and its corresponding \ndata to support progressive interpretation. The T -LMM \nproduces structured interpretations for each chart, which are \nthen evaluated by the same  model, acting as an Evaluator \nLMM (E -LMM), using a predefined rubric to assess clinical \naccuracy and coherence. The highest -scoring interpretation \nis selected as the final output. Through this process, we \nobtain image -derived textual summaries that serve as \nexternal knowledge for the next stage of prediction . \nIn the second stage, we leverage the Student LMM (S -\nLMM), an open -source language model that is deployed \nlocally, to generate future eGFR predictions and clinical \nexplanations. The model is given multiple inputs, including \nthe patient\u2019s eGFR trajectory in chart format, structured \nclinical and laboratory variables, and T -LMM -generated \ninterpretations, which together provide comprehensive \ncontexts for the prediction task. We implement a CoT \nprompting strategy to enhance its reasoning capabilities and \nreduce t he risk of hallucination. Specifically, the S -LMM \nfirst predicts the next eGFR value and then generates an \nexplanation based on the predicted output. This design \nensures that explanations are logically grounded in the \nmodel\u2019s actual prediction, reducing in consistencies or \nfragmented responses. By anchoring the reasoning process \nto the prediction step, the model can explain how specific \ntrends or variables influence the predicted outcome, \nmimicking clinical reasoning .  Since retaining contextual information over time is \ncrucial for coherent reasoning in sequential clinical tasks, \nwe also incorporate a short -term memory mechanism to \nimprove consistency across prediction steps. After each \nprediction, the prompt, predicted value, and explanation are \nstored. When the model proceeds to the next step, it \nretrieves this memory along with the ground truth of the \nprior prediction, allowing it to self -correct and refine its \nreasoning. This mechanism reinforces temporal continuity \nand encourages the model to recognize evolving patterns \nacross time points, thereby improving predictive accuracy . \nTo enhance clinical interpretability, the model generates \nstructured explanations through two complementary forms \nof abductive reasoning [25]: selective abduction, which \ngrounds predictions in observed clinical data [e.g., eGFR \ntrends, blood urea nitrogen (BUN), urine albumin creatinine \nratio (UACR)], and creative abduction, which hypothesizes \nplausible but unobserved factors that could contrib ute to the \npredicted outcome. By combining data -driven and \nhypothesis -based reasoning, the model can generate more \ncomprehensive interpretations and may help mitigate \ndiagnostic bias. It also shows potential as an educational \ntool for training students and  junior clinicians in structured \nclinical reasoning . \nIV. EXPERIMENT S AND DISCUSSION  \nTo demonstrate our proposed method, we utilize data \nfrom the Kaohsiung Medical University Research database. \nThe dataset contains comprehensive variables, including \ndemographic information, clinical biomarkers, and lifestyle \nfactors. Participants were outpatients who received regular  \nfollow -up care from nephrologists at two affiliated hospitals \nof Kaohsiung Medical University between 2004 and 2021.  \nThis study was approved by the Institutional Review Board \nof Kaohsiung Medical University Hospital (KMUHIRB -\nEXEMPT(I) -20210123).  For simplicity, we focus on a \nsubset of 570 observations,  randomly selected from 50 \npatients with varying baseline eGFR levels.  We divided the \npatients into 70% for training and 30% for  validation, while \nmaintaining a similar distribution  of CKD stages across both \nsets to ensure fair evaluation across disease severity levels . \nPredicted eGFR value: 47\nExplanation:\nThe recent upwar d trend in eGFR values may be due \nto temporary improvements or interventions rather \nthan sustained recovery of kidney function. The refore, \na cautious approach suggests predicting a continued \ndecline in eGFR...1\nM plots \nN patients\n5 iterations\nTeacher LMM\n(T-LMM) \nEvaluator LMM\n(T-LMM) \nSelect Best\nIterpretation\nThe patient's eGFR shows significant  fluctuation \nover time. Initially, there's a downward trend, \nfollowed by a slight increase, then a substantial \ndecrease...Student LMM\n(S-LMM) \nKnowledge \nTransferImage Interpretation Prediction and Explanation\nInputs:\n\u25cfClinical + Lab data\n\u25cfDefinitions of Variables\n\u25cfInterpretation from T-LMM\nShort-term Memo ry\ntn-2\ntn-1\ntn\nExplanat ion\nExplanat ion\nExplanat ion\n\n--- Page 4 ---\nTABLE I.  COMPARISON OF MODEL PERFORMANCE WITH DIFFERENT METHODS . \nWe began our experiment by converting each patient\u2019s \nhistorical eGFR measurements into line charts, where the X -\naxis represents the dates of each eGFR measurement, and \nthe Y -axis displays the eGFR values in units of \nmL/min/1.73m\u00b2 . We use Gemini 1.5 Pro [26] as the T\u2011LMM \nto interpret the charts and generate structured visual \nsummaries, which are later provided to the S\u2011LMM for \nprediction tasks. T\u2011LMM extracts clinically relevant \nfeatures from the plots, including identifying inflection  \npoints, assessing recent trends, estimating short -term \nchanges, and classifying kidney status based on CKD \nstaging criteria. Following the previous stage, we input \npatients\u2019 line charts, clinical and laboratory data, and \ninterpretations from T -LMM into S -LMMs, such as Llama \n3.2 [27], [28]  and Gemma 9b [29], to predict eGFR. Before \ngenerating the final prediction, the S -LMM is first prompted \nto predict the two most recent eGFR values. This step helps \nthe model gradually construct an understanding of the \npatient\u2019s trajectory. The interactions from these two \npredictions, including prompts, outputs, and explanations, \nare stored in S -LMM\u2019s short -term memory to support \ncontextual continuity. The model followed a step -wise \nprocess, first generating predictions and then providing \nclinical explanations corresponding to its predictions. This \nsequential chaining approach ensures the explanation is \ngrounded in the model\u2019s prediction, reducing the risk of \nfragmented or incomplete responses . \n We evaluate two types of LMMs on our framework: (1) \nopen -source LMMs, including Llama 3.2 vision 11b and,  \nGemma 3 12b; (2) proprietary models, including GPT -4o \n[22], Gemini 1.5 pro [26]. We also compare our framework to traditional models, including a Random Forest (RF) and \na one -dimensional convolutional neural network (1D -CNN) , \nwhich are only provided with clinical and variable data for \npredictions. Prediction accuracy is assessed using Mean \nSquared Error (MSE) and Mean Absolute Percentage Error \n(MAPE).  \n Our framework is designed to be modular and adaptable, \nallowing different components to be flexibly combined \nbased on model capabilities. For instance, models with \nlimited visual -language integrated capabilities can benefit \nfrom knowledge transfer mechanis ms. In contrast, models \nthat already possess sufficient visual understanding may not \nrequire such assistance and can instead benefit from a short -\nterm memory mechanism. To assess the effectiveness of \neach design choice, we compare configurations with and \nwithout specific components, such as knowledge transfer \nand memory mechanisms, across models with varying \ncapacities. As shown in Table 1, the best overall \nperformance in terms of MAE and MAPE was achieved by \nthe RF model.  However, the model does not provide \ninterpretability or explanatory outputs, which limits its \nclinical applicability.  Furthermore, RF and 1D -CNN require  \ntraining on the entire dataset, whereas LLMs and our \nframework utilize in -context learning.  This allows the \nmodel to make predictions ba sed only on  inference -time \ninputs without the need for retraining . On the other hand, \nGPT -4o delivered the best predictive performance in the \nzero-shot setting among language models and showed \nfurther improvement with the integration of short -term \nmemory.  For open -source/open -weight models, Qwen 2.5 \nvision 32b showed the best result without using any \nModel MethodTrain Validation\nMAE MAPE(%) MAE MAPE(%)\nRF - 1.02 4.35 2.64 11.06\n1D-CNN - 2.76 12.06 2.60 11.74\nLlama 3.2 vision 11Bzero-shot 4.76 19.18 4.33 18.68\nknowledge transfer 3.81 14.86 4.06 31.00\nknowledge transfer + short-term memory 3.62 13.53 3.87 24.54\nGemma 3 12Bzero-shot 4.80 18.60 4.16 17.10\nknowledge transfer 3.76 14.98 3.78 26.90\nknowledge transfer + short-term memory 3.73 15.24 3.84 28.34\nQwen 2.5 vision 32Bzero-shot 2.99 12.46 2.76 12.29\nzero-shot + short-term memory 4.10 14.96 3.46 15.00\nGPT-4ozero shot 2.57 11.66 2.50 11.72\nzero-shot + short-term memory 2.55 11.53 2.55 11.51\nGemini 1.5 Prozero-shot 3.20 13.14 2.82 12.28\nzero-shot + short-term memory 3.13 12.91 2.79 12.30\nGemini 2.0 Prozero-shot 3.21 14.23 3.12 14.37\nzero-shot + short-term memory 3.75 15.40 3.24 15.37\nGemini 2.0 Flashzero-shot 2.64 11.90 2.65 11.78\nzero-shot + short-term memory 2.86 12.92 2.45 11.17\nClaude 3.7 Sonnet \n(self-moderated)zero-shot 2.98 12.86 2.94 12.46\nzero-shot + short-term memory 2.98 13.07 2.69 13.27\n\n--- Page 5 ---\n \nFig. 2.  An example of the prediction and explanation generated by Qwen 2.5 vision.  \ncomplementary techniques.  This demonstrates that strong \nbaseline results are possible with certain architectures.  \nWhile our framework is designed to be modular and \napplicable to any open -source model, we further evaluated \nadditional models to examine the impact of each component. \nLlama 3.2 vision demonstrated substantial gains when both \nknowledge transfer and short -term memory were appli ed, \nachieving an MAE of 3.62 and 3.87 in both training and \nvalidation sets respectively, which is comparable to the \nperformance of proprietary model s. Gemma 3.0 exhibited a \nsimilar improvement under the same enhancements, \nhighlighting the effectiveness of our proposed techniques \nacross different models. In addition to predictive \nperformance, the generated explanations reflected the \nintended abductive reasoning structure. As shown in Figure \n2, the explanations combine a data -driven rationale \nhighlighting historical trends and clinical indicators with \nhypothesis -driven reasoning based on plausible \nassumptions about the patient\u2019s behavior and comorbiditie s. \nIn this study, we demonstrated that our modular \nframework allows diverse LMMs to benefit from improved \neGFR prediction accuracy. One of the main strengths is its \nflexibility, enabling targeted enhancement of weaker \nmodels without the need for retraining. T his design makes \nthe framework more accessible and easier to deploy in \nresource -constrained environments . \nBeyond prediction accuracy, the generated explanations \noffer potential value for real -world applications. One \nimmediate use case is clinical decision support, where the \nmodel\u2019s structured reasoning can help physicians better \nunderstand underlying risk fact ors and the rationale behind \npredicted outcomes. Another promising direction is medical \neducation. This system could be used as a training tool for \nmedical students or junior clinicians by presenting real -\nworld clinical cases alongside AI -generated explana tions. \nSuch use may foster the capabilities of diagnostic reasoning, \ndecision -making skills, and the ability to synthesize \ninformation from multiple clinical variables, which are \ncritical in clinical practice . \nDespite the overall effectiveness of the framework, we \nobserved some unexpected results that warrant further \nconsideration. For instance, Qwen 2.5 Vision 32B \nperformed competitively without using complementary \ntechniques. This may be attributed to stronger  native visual -language integration in its architecture, allowing it to \ninterpret eGFR trajectories without additional support. \nWhile this observation is promising, model -specific \nvariability remains insufficiently understood and may  \ninfluence the choice o f enhancement strategies across \ndifferent settings. . \nThe framework also has certain limitations. It was \ndeveloped and evaluated using a single dataset within a \nspecific clinical context, which may constrain its \ngeneralizability. Furthermore, although the generated \nexplanations are structured and clinically p lausible, their \npractical value in real -world decision -making has yet to be \nvalidated in collaboration with domain experts. Nonetheless, \nthe framework\u2019s modular design and integration of \nreasoning -based explanations offer clear potential for \nbroader applic ation in clinical decision support and medical \ntraining environments . \nV. CONCLUSION  \nWe introduce a collaborative framework that enhances \nthe predictive performance of open -source LMMs for eGFR \nforecasting while providing plausible explanations. The \nproposed framework leverages visual knowledge transfer \nand a short -term memory mechanism to  address limitations \nin existing models. It also employs abductive reasoning to \ngenerate clinical explanations from observed data and \nplausible hypotheses. Our experimental results show that \nthe framework achieves prediction accuracy comparable to \npropriet ary models, while maintaining the flexibility and \nprivacy benefits of open -source deployment. This approach \nprovides a clinically applicable and interpretable solution \nfor eGFR prediction, enabling accurate risk monitoring \nwhile supporting local, privacy -preserving deployment . \nACKNOWLEDGMENT  \nThis study is mainly supported by the National Health  \nResearch Institutes (NHRI -EX114 -11208PI) . \nREFERENCES  \n[1] R. J. Glassock, D. G. Warnock, and P. Delanaye, \u201cThe global burden \nof chronic kidney disease: estimates, variability and pitfalls,\u201d Nat \nRev Nephrol , vol. 13, no. 2, pp. 104 \u2013114, Feb. 2017, doi: \n10.1038/nrneph.2016.163.  \n[2] L. Chu et al. , \u201cAWAREness of Diagnosis and Treatment of Chronic \nKidney Disease in Adults With Type 2 Diabetes (AWARE -CKD in \nPredictedeGFR value :11.8\n(A)Selecti veAbduction (Data-drivenExplana tion)\n(B)CreativeAbduction (Hypothesis-drivenExplana tion)The consistent historical declin e in eGFR, combi ned with  \nthe pa tient's diabet es, severe albumi nuria, smoking s tatus, \nand elevated BUN,  strongly supports the predictio n of a \nfurth er declin e in eGFR to 11.8  mL/min/ 1.73m\u00b2 over the \nnext 35 days.\nAssumptions:\n1.UncontrolledBloo dGluc oseLevels:Whileblood glucoselevelsarenotprovidedinthe\ndata,assumingthatthepatient\u2019sdiabet esisnotoptima llycontrolledcouldacceler atethe\ndeclin eineGFR .\n2.InadequateComplianc ewith Treatmen t:Thepatientmaynotbeadhering to\nprescribedtreatments(e.g.,ACEinhibitors/ARBs,antihypertensives,orblood glucose\nmanag emen t).Non -compl iance couldlead toafasterdeclin einkidneyfunction .\n...\n\n\n--- Page 6 ---\nT2D),\u201d Canadian Journal of Diabetes , vol. 46, no. 5, pp. 464 \u2013472, \nJul. 2022, doi: 10.1016/j.jcjd.2022.01.008.  \n[3] A. A. Killeen and G. L. Horowitz, \u201cNew Equations for Estimating \nGlomerular Filtration Rate,\u201d Clinical Chemistry , vol. 68, no. 4, pp. \n491\u2013493, Nov. 2021, doi: 10.1093/clinchem/hvab260.  \n[4] C. Xiao, E. Choi, and J. Sun, \u201cOpportunities and challenges in \ndeveloping deep learning models using electronic health records \ndata: a systematic review,\u201d Journal of the American Medical \nInformatics Association , vol. 25, no. 10, pp. 1419 \u20131428, Oct. 2018, \ndoi: 10.1093/jamia/ocy068.  \n[5] R. Bommasani et al. , \u201cOn the Opportunities and Risks of \nFoundation Models,\u201d Jul. 12, 2022, arXiv : arXiv:2108.07258. doi: \n10.48550/arXiv.2108.07258.  \n[6] J. Clusmann et al. , \u201cThe future landscape of large language models \nin medicine,\u201d Commun Med , vol. 3, no. 1, pp. 1 \u20138, Oct. 2023, doi: \n10.1038/s43856 -023-00370 -1. \n[7] C.-Y. Li, J. -T. Wu, C. Hsu, M. -Y. Lin, and Y. Kang, \n\u201cUnderstanding eGFR Trajectories and Kidney Function Decline \nvia Large Multimodal Models,\u201d Sep. 04, 2024, arXiv : \narXiv:2409.02530. doi: 10.48550/arXiv.2409.02530.  \n[8] Z. A. Nazi and W. Peng, \u201cLarge language models in healthcare and \nmedical domain: A review,\u201d in Informatics , MDPI, 2024, p. 57.  \n[9] A. Mohtashami, F. Hartmann, S. Gooding, L. Zilka, M. Sharifi, and \nB. A. y Arcas, \u201cSocial Learning: Towards Collaborative Learning \nwith Large Language Models,\u201d Feb. 08, 2024, arXiv : \narXiv:2312.11441. doi: 10.48550/arXiv.2312.11441.  \n[10] J. Wei et al. , \u201cChain -of-thought prompting elicits reasoning in large \nlanguage models,\u201d Advances in neural information processing \nsystems , vol. 35, pp. 24824 \u201324837, 2022.  \n[11] J. R. Hobbs, M. E. Stickel, D. E. Appelt, and P. Martin, \n\u201cInterpretation as abduction,\u201d Artificial Intelligence , vol. 63, no. 1, \npp. 69 \u2013142, 1993, doi: https://doi.org/10.1016/0004 -\n3702(93)90015 -4. \n[12] A. Francis et al. , \u201cChronic kidney disease and the global public \nhealth agenda: an international consensus,\u201d Nat Rev Nephrol , vol. \n20, no. 7, pp. 473 \u2013485, Jul. 2024, doi: 10.1038/s41581 -024-00820 -\n6. \n[13] P. E. Stevens et al. , \u201cKDIGO 2024 Clinical Practice Guideline for \nthe Evaluation and Management of Chronic Kidney Disease,\u201d \nKidney International , vol. 105, no. 4, pp. S117 \u2013S314, Apr. 2024, \ndoi: 10.1016/j.kint.2023.10.018.  \n[14] C.-C. Kuo et al. , \u201cAutomation of the kidney function prediction and \nclassification through ultrasound -based kidney imaging using deep \nlearning,\u201d npj Digital Medicine , vol. 2, no. 1, p. 29, Apr. 2019, doi: \n10.1038/s41746 -019-0104 -2. \n[15] T. Ferguson et al. , \u201cDevelopment and External Validation of a \nMachine Learning Model for Progression of CKD,\u201d Kidney Int Rep , \nvol. 7, no. 8, pp. 1772 \u20131781, Aug. 2022, doi: \n10.1016/j.ekir.2022.05.004.  \n[16] G. Schwalbe and B. Finzel, \u201cA comprehensive taxonomy for \nexplainable artificial intelligence: a systematic survey of surveys on \nmethods and concepts,\u201d Data Mining and Knowledge Discovery , \nvol. 38, no. 5, pp. 3043 \u20133101, Sep. 2024, doi: 10.1007/s10618 -022-\n00867 -8. \n[17] S. Lundberg and S. -I. Lee, \u201cA Unified Approach to Interpreting \nModel Predictions,\u201d Nov. 25, 2017, arXiv : arXiv:1705.07874. doi: \n10.48550/arXiv.1705.07874.  \n[18] M. T. Ribeiro, S. Singh, and C. Guestrin, \u201c\u2018Why Should I Trust \nYou?\u2019: Explaining the Predictions of Any Classifier,\u201d in \nProceedings of the 22nd ACM SIGKDD International Conference \non Knowledge Discovery and Data Mining , San Francisco \nCalifornia USA: ACM, Aug. 2016, pp. 1135 \u20131144. doi: \n10.1145/2939672.2939778.  \n[19] B. R. Kim, K. Srinivasan, S. H. Kong, J. H. Kim, C. S. Shin, and S. \nRam, \u201cROLEX: A Novel Method for Interpretable Machine \nLearning Using Robust Local Explanations.,\u201d MIS Quarterly , vol. \n47, no. 3, 2023.  \n[20] S. Hegselmann, A. Buendia, H. Lang, M. Agrawal, X. Jiang, and D. \nSontag, \u201cTabLLM: Few -shot Classification of Tabular Data with Large Language Models,\u201d in Proceedings of The 26th International \nConference on Artificial Intelligence and Statistics , PMLR, Apr. \n2023, pp. 5549 \u20135581. Accessed: May 10, 2025. [Online]. Available: \nhttps://proceedings.mlr.press/v206/hegselmann23a.html  \n[21] G. Team et al. , \u201cGemini: A Family of Highly Capable Multimodal \nModels,\u201d Jun. 17, 2024, arXiv : arXiv:2312.11805. doi: \n10.48550/arXiv.2312.11805.  \n[22] OpenAI et al. , \u201cGPT -4o System Card,\u201d Oct. 25, 2024, arXiv : \narXiv:2410.21276. doi: 10.48550/arXiv.2410.21276.  \n[23] W. Yu et al. , \u201cMm -vet v2: A challenging benchmark to evaluate \nlarge multimodal models for integrated capabilities,\u201d arXiv preprint \narXiv:2408.00765 , 2024.  \n[24] Z. Zhang et al. , \u201cA Survey on the Memory Mechanism of Large \nLanguage Model based Agents,\u201d Apr. 21, 2024, arXiv : \narXiv:2404.13501. doi: 10.48550/arXiv.2404.13501.  \n[25] S. S. Gouveia and J. Mal\u00edk, \u201cCrossing the Trust Gap in Medical AI: \nBuilding an Abductive Bridge for xAI,\u201d Philos. Technol. , vol. 37, \nno. 3, p. 105, Aug. 2024, doi: 10.1007/s13347 -024-00790 -4. \n[26] G. Team et al. , \u201cGemini 1.5: Unlocking multimodal understanding \nacross millions of tokens of context,\u201d arXiv preprint \narXiv:2403.05530 , 2024.  \n[27] A. Dubey et al. , \u201cThe Llama 3 Herd of Models,\u201d Aug. 15, 2024, \narXiv : arXiv:2407.21783. doi: 10.48550/arXiv.2407.21783.  \n[28] \u201cmeta -llama/Llama -3.2-11B-Vision -Instruct \u00b7 Hugging Face.\u201d \nAccessed: May 14, 2025. [Online]. Available: \nhttps://huggingface.co/meta -llama/Llama -3.2-11B-Vision -Instruct  \n[29] G. Team et al. , \u201cGemma 3 technical report,\u201d arXiv preprint \narXiv:2503.19786 , 2025.",
  "project_dir": "artifacts/projects/Interpretable Renal Health Decline Forecasting",
  "communication_dir": "artifacts/projects/Interpretable Renal Health Decline Forecasting/.agent_comm",
  "assigned_at": "2025-07-31T21:28:33.750406",
  "status": "assigned"
}